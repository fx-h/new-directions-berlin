---
title: | 
    | Sensitivity Analyses
author: "Ryan T. Moore"
date: 2024-07-16
date-format: iso
execute: 
  echo: true
format: 
  beamer:
    fonttheme: serif
    include-in-header:
      - text: |
          \usepackage{ulem}
          \usepackage{wasysym}
          \newcommand{\independent}{\perp\mkern-9.5mu\perp}
    section-titles: true
    toc: true
institute:
  - American University
  - The Lab @ DC
bibliography: "../admin/main.bib"
---

```{r}
#| label: setup
#| echo: false
#| message: false
#| results: false
#| warning: false

library(ggdag)
library(here)
library(knitr)
library(scales)
library(tidyverse)
```

# Sensitivity

## What is "sensitivity"?

\LARGE

When inputs change, do outputs change?

\pause 

>- With different variables in model, does parameter of interest change?
>- With different assumptions about error structures, does causal mediation estimate change?
>- With different data collected, would causal conclusion change?

<!-- Include PDFs in columns -->
<!-- \includegraphics[width=2in]{figs/myfig1.pdf} -->
<!-- \includegraphics[width=2in]{figs/myfig2.pdf} -->

# Sensitivity to Model Specification

## Should we trust our model?

\large

Suppose I present observational results:

\footnotesize
\begin{table}[!ht]
\begin{tabular}{lc}
& Coefficient \\ \hline
$\geq$ 1000 auto workers      & 0.87     \\
                              & (0.39)      \\
DW-NOMINATE                   & -5.04   \\
                              & (0.53)      \\
Ford/Chrysler/GM PAC Contribs (log) &        0.15  \\
                                    &        (0.05)      \\
AFL-CIO PAC Contribs (log)          &        0.09     \\
                                    &       (0.04) \\ 
Intercept & -0.14 \\
          & (0.30)      \\ \hline
$N$ & 406         \\
AIC & 258.59      \\
BIC & 338.72      \\
$\log L$    & -109.30     \\ \hline
\end{tabular}
\end{table}

<!-- \multicolumn{2}{l}{\footnotesize{Standard errors in parentheses}}\\ -->
<!-- \end{tabular} -->
<!-- \caption{Logistic Regression Coefficients of Support for House Roll Call 690, Congressional Session 110.2. Vote on 10 December 2008 for using TARP for auto bailout. Passed 237-170: Democrats 205-20, Republicans 32-150.} -->

\pause 
\normalsize

What would be your questions?

## Multiplicity of Models

\large

>- For $k$ predictors, there are $2^k$ possible models
>- For 30 predictors, $10^9$ possible models
>- ($7\times$ as many km to the sun!)
>- So, typically, we show

## Multiplicity of Models

\scriptsize
\begin{table}[!ht]
 \begin{tabular}{lcccc} \hline 
  & Model 1 & Model 2 & Model 3 & Model 4 \\ \hline
Intercept                           & 2.12  & 0.61   & 1.26  & -0.14       \\ 
                                    & (0.24)       & (0.20)       & (0.31)       & (0.30)      \\ 
$\geq$ 1000 auto workers           & 0.98   & 1.14   & 0.74      & 0.87    \\ 
                                    & (0.34)       & (0.37)       & (0.36)       & (0.39)      \\ 
Republican                          &  &              &  &             \\ 
                                    & (0.33)       &              & (0.42)    &             \\ 
DW-NOMINATE                         &              & -4.87 &              & -5.04\\ 
                                    &              & (0.42)       &              & (0.53)      \\ 
Ford/Chrysler/GM PAC Contribs (log) &              &              & 0.14   & 0.15 \\ 
                                    &              &              & (0.05)       & (0.05)      \\ 
AFL-CIO PAC Contribs (log)          &              &              & 0.14  & 0.09   \\ 
                                    &              &              & (0.04)       & (0.04)      \\ \hline
$N$                                 & 407          & 406          & 407          & 406         \\ 
AIC                                 & 301.48       & 268.76       & 284.11       & 258.59      \\ 
BIC                                 & 349.58       & 316.83       & 364.29       & 338.72      \\ 
$\log L$                           & -138.74      & -122.38      & -122.06      & -109.30     
\\ \hline
\end{tabular}
\end{table}

\pause 

\normalsize
Rather than small set of substantively-informed models, just show them all!



## Example 1: Congressional Auto Industry Support

\large

>- "Great Recession" following global financial crisis of 2008-2009 ("subprime mortage crisis")
>- Two big bills in US Congress to shore up US auto industry
>    - Auto Bailout: $80bn to GM and Chrysler
>    - Cash for Clunkers: $3bn to consumer rebates

\pause 

@moopowree13: two quasi-private, particularistic bills.

Estimate relationship 

(presence of auto factories) $\Rightarrow$ (Congressional votes) 

\pause 

Claim: **Local econ interests** at least on par w/ corporate campaign contributions, lobbying, public positions.

## @moopowree13

![First diffs, predicted prob MoC supports auto bailout, member from industry v. non-industry district, other vars at means.](figs/02-fd690dwFac.pdf){fig_align="center" height=80%}

## @moopowree13

![First diffs, industry v. non-industry district member prob of supporting bailout positive at any value of DW-NOMINATE score. Mean ests: black discs; 95% CI: red vertical bars. Rug: (jittered) DW-NOMINATE scores for Ds, Rs, and party defectors.](figs/02-fd690dwDW.pdf){fig_align="center" height=80%}



## Insensitivity to Specification

![Industry presence coef always positive in Bailout logistic regressions. Coef densities w/ industry presence and DW-NOMINATE always included. Every comb'n of other vars included and excluded: contributions from Big 3 PAC, AFL-CIO PAC, AFIT-PAC, Auto Dealers PAC, Foreign Auto Dealers PAC, Auto Dealers and Drivers PAC, Transit Union Workers PAC. PAC contributions logged. Panel title gives entire range of coef SEs.](figs/02-bailoutLogDWall.pdf){fig_align="center" height=80%}

## Insensitivity to Specification

![Industry presence coef always positive in Cash for Clunkers logistic regressions. Coef densities w/ industry presence and DW-NOMINATE always included. Every comb'n of other variables included and excluded: contributions from Big 3 PAC, AFL-CIO PAC, AFIT-PAC, Auto Dealers PAC, Foreign Auto Dealers PAC, Auto Dealers and Drivers PAC, Transit Union Workers PAC. PAC contributions logged. Panel title gives entire range of coef SEs.](figs/02-clunkersLogDWall.pdf){fig_align="center" height=80%}

## Implementation

\large

```{r}
library(olsrr)
```

>- Estimate (all) linear models
>- Provide model fit stats
>- Provide coefs

\pause 

@hebbali24


## Example 2: Social Pressure Mailers

\pause 

![](figs/02-gg-neighbors.png)


## Example 2: Social Pressure Mailers

```{r}
library(qss)
data(social)
```

```{r}
#| echo: false

social <- social |> mutate(
  age = 2006 - yearofbirth,
  messages = fct_relevel(messages, "Control")
)
```

```{r}
social |> select(-yearofbirth) |> head()
```


## Example 2: Social Pressure Mailers

```{r}
#| cache: true

lm_out <- lm(primary2006 ~ messages + sex + age +
               primary2004 + hhsize, data = social)

all_lm_social <- ols_step_all_possible(lm_out)$result

dim(all_lm_social)
head(all_lm_social)
```

## Example 2: Social Pressure Mailers

```{r}
all_lm_social_coefs <- ols_step_all_possible_betas(lm_out)

all_lm_social_coefs
```

## Example 2: Social Pressure Mailers

```{r fig.height=5}
#| label: fig-coefs-neighbors
#| echo: false
#| fig-cap: "'Neighbors' Coefs from All Possible Regressions"

coefs_neighbors <- all_lm_social_coefs |> filter(predictor == "messagesNeighbors")

ggplot(coefs_neighbors, aes(beta)) + geom_histogram() + 
  labs(x = "Coefficient on 'Neighbors' Message")
```

```{r}
#| echo: false
summary(coefs_neighbors$beta)
```

## All Coefficients

```{r}
#| label: fig-coefs-all-neighbors
#| echo: false
#| fig-cap: "Coefs from All Possible Regressions"

ggplot(all_lm_social_coefs, aes(x = beta)) + geom_density() + 
  facet_wrap(~ predictor, scales = "free") +
  scale_x_continuous(labels = label_number(0.001))
```

## Preprocessing to Control Sensitivity

\large 

>- So far, "show all the models"
>- Better: preprocess data to minimize effects of model-based adjustment 
>- Match, subclassify

\pause 

"model-based adjustments \ldots will give basically the same point estimates"

## Matching

\large

| $X$ | $T$ | $Y(0)$ | $Y(1)$ | $Y^{\text{obs}}$ |
| :-: | :-: | :-: | :-: | :-: |
|  1  |  1  |   1    |   2    |        2         |
|  1  |  0  |   1    |   2    |        1         |
|  1  |  0  |   1    |   2    |        1         |
|  2  |  1  |   2    |   3    |        3         |
|  2  |  1  |   2    |   3    |        3         |
|  2  |  0  |   2    |   3    |        2         |

\pause 

>- $\tau_i = 1 \quad \forall i$
>- $ATE = \overline{Y(1)-Y(0)}= 1$
>- $\widehat{ATE} = \left(\overline{Y(1)}|T = 1 \right) - \left( \overline{Y(0)}|T=0 \right) 
= \frac{8}{3} - \frac{4}{3} = \frac{4}{3}$


## Matching

\large

Suppose we 1:1 exact match on $X$:

| $X$ | $T$ | $Y(0)$ | $Y(1)$ | $Y^{\text{obs}}$ |
| :-: | :-: | :-: | :-: | :-: |
|  1  |  1  |   1    |   2    |        2         |
|  1  |  0  |   1    |   2    |        1         |
| \sout{1} | \sout{0}  | \sout{1} | \sout{2}    | \sout{1} |
|  2  |  1  |   2    |   3    |        3         |
|  \sout{2}  |  \sout{1}  |   \sout{2}    |   \sout{3}    |        \sout{3}         |
|  2  |  0  |   2    |   3    |        2         |

<!-- | $X$ | $T$ | $Y(0)$ | $Y(1)$ | $Y^{\text{obs}}$ | -->
<!-- | :-: | :-: | :----: | :----: | :--------------: | -->
<!-- |  1  |  1  |   1    |   2    |        2         | -->
<!-- |  1  |  0  |   1    |   2    |        1         | -->
<!-- | \color{lightgray}{1} |  \color{lightgray}{0}  |   \color{lightgray}{1} |   \color{lightgray}{2}    | \color{lightgray}{1} | -->
<!-- |  2  |  1  |   2    |   3    |        3         | -->
<!-- |  \color{lightgray}{2}  |  \color{lightgray}{1}  |   \color{lightgray}{2}    |   \color{lightgray}{3}    |        \color{lightgray}{3}         | -->
<!-- |  2  |  0  |   2    |   3    |        2         | -->

\pause 

$$\widehat{ATE}_m = \left(\overline{Y_m(1)}|T=1 \right) - \left( \overline{Y_m(0)} |T=0 \right)
= \frac{5}{2} - \frac{3}{2} = 1$$
\pause 
Not just coincidence; matching removes $X \to T$.



## @hoimakin07

"Matching as Nonparametric Preprocessing for Reducing Model Dependence in Parametric Causal Inference"

![Before: Direction of Effect depends on Model. After: Effect indendent of Model.](figs/02-hiks-model-dep.png)



## Reducing Sensitivity in FDA Example

![](figs/02-hiks-fda.png)

## How to Identify Sensitivity?

Different distributions; non-overlap

![](figs/02-hiks-qq-candviz.png){fig-align="center" height=80%}

## Reducing Sensitivity in Candidate Visibility Example

![](figs/02-hiks-candviz.png)


## Paradox of Regression for causal inference?

\Large 

>- If large diffs in distn's,  
$\rightsquigarrow$ regression not enough, very sensitive
>- If small diffs in distn's,  
$\rightsquigarrow$ regression won't matter much 
<!-- - @hoimakin07 -->

## Dynamic Treatment Regimes

\pause 

![](figs/02-blastr-dynamic.png)


@blastr22 



## Telescope Matching 

\large

Preprocessing for Dynamic Treatment Regimes:

>- Match across early Tr ($A_1$) on baseline covariates $X$
>- Match across late Tr ($A_2$) on early Tr (exact), baseline $+$ intermediate covariates ($A_1$, $X$, $Z$ [or $X_1$, $X_2$]) 
>- Use matches to impute "paths not taken"

## Telescope Matching 

\large

Preprocessing for Dynamic Treatment Regimes:

Diff-in-means estimator for effect of "early treatment":

$$\hat{\tau} \equiv \frac{1}{N} \sum\limits_{i=1}^N \left( \hat{Y}_i(1,0) - \hat{Y}_i(0,0) \right)$$

## Telescope Matching Example

```{r}
library(DirectEffects)
data(jobcorps)
```

* $Y$: self-reported good health (0/1)
* $X1$: school/training/job before Job Corps
* $A1$: Job Corps program
* $X2$: employment in Q4 after assg
* $A2$: employment in Q just before outcome

\pause 

```{r}
# Formula: Y ~ X1 | A1 | X2 | A2

tm_form <- exhealth30 ~ schobef + trainyrbef + 
  jobeverbef | treat | emplq4 + emplq4full | work2year2q

tm_out <- telescope_match(tm_form, data = jobcorps, verbose = FALSE)
```

## Telescope Matching Example

```{r}
tm_out
```


## Telescope Matching Example

\tiny
```{r}
summary(tm_out)
```



# Sensitivity to an Unidentifiable Parameter

## Mediation Analysis

Confounding in Observational Studies

```{r warning = FALSE}
#| echo: false
coords <- list(x = c(T = 0, X = 1, Y = 2, M = 1),
               y = c(T = 1, X = 0, Y = 1.1, M = 1.5))
dagify(Y ~ T + M, T ~ X, Y ~ X, M ~ T, coords = coords) |>
  ggdag_classic(size = 30) + theme_dag_blank()
```

## Mediation Effects

\Large

>- If interest is $M \to Y$, seek experiment-like $M$
>    - random $M$
>    - subclassify/match for $M$
>    - instrumented $M$
>    - RDD, synthetic control for $M$
>- If interest is $T \to Y$, seek experimental $T$
>    - random $T$
>    - subclassify/match for $T$
>    - instrumented $T$
>    - RDD, synthetic control for $T$
>- In _mediation_, interest is $T \to M \to Y$
>    - (and maybe $T \to (\lnot M) \to Y$)


## Mediation Effects

\Large

Condition on /control for $M$?

\pause

>- No: how to estimate $M \to Y$?
>- Yes: induces _post-treatment bias_ in estimate of $T \to Y$

\pause

>- And if $X \to M$, too?
>- Even worse \ldots

***

```{r warning = FALSE}
#| echo: false
coords <- list(x = c(T = 0, X = 1, Y = 2, M = 1.1),
               y = c(T = 1, X = 0, Y = 1.1, M = 1.5))
dagify(Y ~ T + M, T ~ X, Y ~ X, M ~ T + X, coords = coords) |>
  ggdag_classic(size = 30) + theme_dag_blank()
```


## Addressing Confounding

\Large

To break confounding,

>- can't break $X \to Y$
>- break $X \to T$
>- but $X \to M$ may still remain!

<!-- # Post-Treatment Bias -->

## Post-Treatment Bias

<!-- <!-- \note{ --> 
<!-- <!--   \begin{itemize} --> 
<!-- <!--   \item Assumption: randomized experiment, no bias from --> 
<!-- <!--     self-assignment to treatment --> 
<!-- <!--   \item Assumption: perfect compliance --> 
<!-- <!--   \item Plot: (Pr(Lung Cancer) $\sim$ smoking status) --> 
<!-- <!--   \end{itemize} --> 

- Interest in effect of news on attitude. \pause  Randomly assign news:
```{r warning = FALSE}
n <- 200
news <- sample(0:1, n, replace = TRUE)
```

## Post-Treatment Bias

- News status greatly affects Anxiety:

```{r fig.height=4.5}
#| echo: true
pr.anx <- 1/(1 + exp(-(news * 2 + rnorm(n))))
```
\pause

```{r fig.height=4}
#| echo: false
pt <- tibble(news, pr.anx)
ggplot(pt, aes(news, pr.anx, group = news)) + geom_boxplot() + labs(x = "News", y = "Anxiety")
```

## Post-Treatment Bias

- News status greatly affects Anxiety:

```{r}
summary(lm(pr.anx ~ news))$coef |> round(3)
```

<!-- <!-- \vspace{-3mm} --> 
<!-- <!--  \begin{center} --> 
<!-- <!--  \includegraphics[angle=0, width=2.2in]{../figs/ptTrend} --> 
<!-- <!--  \end{center} --> 


## Post-Treatment Bias

<!-- <!-- \note{ --> 
<!-- <!--   \begin{itemize} --> 
<!-- <!--   \item (linear predictor of) mortality is function of Tr,  -->
<!-- <!--   \item Whether you're nonsmoker or smoker, lung cancer --> 
<!-- <!--     incr. mortality --> 
<!-- <!--     \item But {\it clearly}, smokers more likely to get LC, and have higher mortality --> 
<!-- <!--   \end{itemize} --> 
<!-- <!-- } --> 

>- Anxiety greatly increases (negative) attitude
>    - (but news also has other ways to increase negative attitude)

\pause

```{r}
attitude <- .1 * news + pr.anx + rnorm(n, sd = 0.2)
```

```{r}
#| echo: false
pt <- tibble(news, pr.anx, attitude)
```

\pause

```{r fig.height=4}
#| echo: false
ggplot(pt, aes(pr.anx, attitude)) + geom_point() + geom_smooth() + facet_wrap(~ news)
```

<!-- <!-- \vspace{-3mm} --> 
<!-- <!--  \begin{center} --> 
<!-- <!--  \includegraphics[angle=0, width=2.6in]{../figs/ptBias} --> 
<!-- <!--  \end{center} --> 


## Post-Treatment Bias

\large

<!-- <!--   \begin{itemize} --> 
<!-- <!--   \item Analysis 1: no effect of smoking!! --> 
<!-- <!--   \item Analysis 2: clear effect of smoking --> 
<!-- <!--     ($1.4\sigma_y^{\text{controls}}$) --> 
<!-- <!--   \item Note: Tr was randomly assigned!  I have no other confounders. --> 
<!-- <!--     If Tr {\it nonrandomly} assigned, I have all the usual obs. study --> 
<!-- <!--     problems, plus possibility of post-treatment bias. --> 
<!-- <!--   \end{itemize} --> 

>- Interested in causal effect of news on attitude
>- Analysis 1: Adjust for anxiety status:

\pause

```{r warning = FALSE}
summary(lm(attitude ~ news + pr.anx))$coef |> round(4)
```

<!-- <!--             Estimate Std. Error t value Pr(>|t|)     --> 
<!-- <!-- (Intercept)  0.04955    0.06152   0.805    0.423     --> 
<!-- <!-- smoke        0.03881    0.05348   0.726    0.470     --> 
<!-- <!-- pr.lc        0.95007    0.11028   8.615  1.3e-13 *** --> 

\pause

>- Great! Now, say, multiply coefs, to get $T \to M \to Y$?
>- Problem: This doesn't work.

## Post-Treatment Bias

\large

<!-- <!--   \begin{itemize} --> 
<!-- <!--   \item Analysis 1: no effect of smoking!! --> 
<!-- <!--   \item Analysis 2: clear effect of smoking --> 
<!-- <!--     ($1.4\sigma_y^{\text{controls}}$) --> 
<!-- <!--   \item Note: Tr was randomly assigned!  I have no other confounders. --> 
<!-- <!--     If Tr {\it nonrandomly} assigned, I have all the usual obs. study --> 
<!-- <!--     problems, plus possibility of post-treatment bias. --> 
<!-- <!--   \end{itemize} --> 

>- Interested in causal effect of news on attitude
>- Analysis 2: Don't control for anxiety status:

\pause

```{r}
summary(lm(attitude ~ news))$coef |> round(4)
```

<!-- <!--  summary(lm(lp.mort ~ smoke)) --> 
<!-- <!--             Estimate Std. Error t value Pr(>|t|)     --> 
<!-- <!-- (Intercept)  0.52174    0.03694   14.13  < 2e-16 *** --> 
<!-- <!-- smoke        0.37395    0.04850    7.71 1.05e-11 *** --> 

\pause

>- Great! Now, say, subtract coef Analysis 1 from this, to get $T \to M \to Y$?
>- Problem: This doesn't work.

## Post-Treatment Bias

<!-- <!-- The roughest, rawest advice. --> 
<!-- <!-- Draw the Tr timing arrow. --> 

If you want the effect of $T$ on $Y$,

\begin{itemize}
\item Match/adjust for (pre-treatment) covariates
\item Don't match/adjust for other (post-treatment) quantities
\end{itemize}

\pause

If I'm not sure about the causal ordering, can I just try both?
\pause

Idea:

>- Estimate $Y_i = \beta_0 + \beta_1 T_i + \epsilon_i$
>- Estimate $Y_i = \delta_0 + \delta_1 T_i + \delta_2 X_i + \nu_i$ \pause

Problem:

>- These 2 estimates of TE **don't** bound the truth.
>- $ATE \stackrel{?}{\in} [\hat{\beta}_1, \hat{\delta}_1 ]$ \pause  We don't know!

<!-- ## Post-Treatment Bias -->

<!-- \large -->

<!-- >- Think really hard about design. -->
<!-- >- Some ideas -->
<!-- >    - Redefine the treatment (audit studies) -->
<!-- >    - Find a valid instrument/discontinuity/milestone/opportunity -->
<!-- >    - Plan an experiment -->
<!-- >    - Plan several experiments -->

## Mediation

<!-- <!-- In the example, --> 
<!-- <!-- \begin{itemize} --> 
<!-- <!-- \item Treatment: smoking --> 
<!-- <!-- \item Mechanism/mediator: lung cancer \pause  --> 
<!-- <!-- \item Key: we've shown that even if $T$ randomized, adjusting for $M$ gives biased --> 
<!-- <!--   estimate of causal effect \pause  --> 
<!-- <!-- \item Ok, I want effect of smoking on mortality that {\it goes --> 
<!-- <!--     through} lung cancer --> 
<!-- <!-- \end{itemize} --> 

<!-- ## Mediation Exercise -->

<!-- <!-- \note{ --> 
<!-- <!-- Not just direction. --> 
<!-- <!-- \begin{enumerate} --> 
<!-- <!-- \item Reminds voter of election day; heightens sense of party-team --> 
<!-- <!--   identity --> 
<!-- <!-- \item Kids can focus in class; nicer groceries and kids eat better --> 
<!-- <!-- \item Make opponent look supportive of outgroup; heighten fear of --> 
<!-- <!--   fiscal armeggedon --> 
<!-- <!-- \end{enumerate} --> 
<!-- <!-- } --> 

<!-- Describe two mechanisms through which -->

<!-- \begin{enumerate} -->
<!-- \item a GOTV prompt could increase turnout -->
<!-- \item neighborhood safety could increase GPA -->
<!-- \item a political attack advertisement could increase propensity to vote for -->
<!--   anti-welfare state candidate -->
<!-- \end{enumerate} -->

<!-- \pause -->
<!-- \vspace{3mm} -->

Mediation analysis tries to estimate _how much_ effect of $T$ on
$Y$ goes through $M$.



## Notation

<!-- <!-- \note{ --> 
<!-- <!-- (Assuming perfect compliance.) --> 

<!-- <!-- \begin{itemize} --> 
<!-- <!-- \item Q: Is $M_i(t)$ a potential outcome?\\ --> 
<!-- <!-- \item[] A: Yes.  Fixed, value revealed based on $t$. --> 
<!-- <!-- \item Quiz: --> 
<!-- <!-- \begin{itemize} --> 
<!-- <!--   \item what's $Y_i(1, M_i(1))$?  mortality would obs given smoking and LC you'd --> 
<!-- <!--     get under smoking. --> 
<!-- <!--    \item what's $Y_i(0, M_i(0))$? mortality would obs given nonsmoking and LC --> 
<!-- <!--      you'd get under nonsmoking.  ($M_i(0)$ may $=1$: still get LC.) --> 
<!-- <!--   \item what's $Y_i(1, M_i(1)) - Y_i(0, M_i(0))$?   Total mortality --> 
<!-- <!--     difference would obs. for $i$ under smoking minus $i$ under nonsmoking, just --> 
<!-- <!--     letting LC vary as it will under each assg. --> 
<!-- <!--     \item what's $Y_i(1, M_i(0))$?  mortality would obs under smoking, but LC --> 
<!-- <!--       value from nonsmoking.  (Jason...)  (Imagine randomizing LC values.) --> 
<!-- <!-- \end{itemize} --> 
<!-- <!-- \end{itemize} --> 
<!-- <!-- } --> 

<!-- <!-- %Welcome back to ``compliance''.  \pause You know this can --> 
<!-- <!-- %clarify underlying ideas.  \pause  --> 

\begin{itemize}
\item $M_i(t)$: value of the mediator (function of treatment) \pause
\item $Y_i(t,m)$: potential outcome under some combination of $t$, $m$
  \pause
\item $Y_i(T_i, M_i(T_i))$: potential outcome under
  \begin{itemize}
  \item $T_i = t$
  \item $M_i$ you would get with $T_i=t$
  \end{itemize} \pause
\item Quiz: \pause  In news/anxiety/attitude example,
  \begin{itemize}
  \item what's $Y_i(1, M_i(1))$?
   \item what's $Y_i(0, M_i(0))$?
  \item what's $Y_i(1, M_i(1)) - Y_i(0, M_i(0))$?
  \item what's $Y_i(1, M_i(0))$?
  \end{itemize}
\end{itemize}


## Notation: Causal Effects

<!-- <!--   \begin{itemize} --> 
<!-- <!--   \item Mediation effects: hold Tr/Co constant, manipulate mediator --> 
<!-- <!--   \item Direct effects: hold mediator constant, manipulate --> 
<!-- <!--     Tr/Co. (``zeta'') --> 
<!-- <!-- \item Note: Plural -- ``effectS'' --> 
<!-- <!-- \item Immig -- Mediation: effect of changing anxiety on opinion (for fixed --> 
<!-- <!--   Tr status). --> 
<!-- <!-- \item Immig -- Direct: effect of exposure on opinion, holding anxiety fixed. --> 
<!-- <!--   \end{itemize} --> 

For individuals:
\begin{itemize}
\item $Y_i(1, M_i(1)) - Y_i(0, M_i(0))$: Total effect \pause
\item $Y_i(0, M_i(1)) - Y_i(0, M_i(0)) \equiv \delta_i(0)$:
  Indirect/Mediation effect under Co
\item $Y_i(1, M_i(1)) - Y_i(1, M_i(0)) \equiv \delta_i(1)$:
  Indirect/Mediation effect under Tr  \pause
\item ACMEs: $\bar{\delta}(1)$ and $\bar{\delta}(0)$ \pause
\item $Y_i(1, M_i(0)) - Y_i(0, M_i(0))\equiv \zeta_i(0)$: Direct
  effect of Tr on $Y$,\\ under mediator value as if control
\item $Y_i(1, M_i(1)) - Y_i(0, M_i(1))\equiv \zeta_i(1)$: Direct
  effect of Tr on $Y$,\\ under mediator value as if treated \pause
\item ADEs: $\bar{\zeta}(1)$ and $\bar{\zeta}(0)$ \pause
\end{itemize}

<!-- ## Notation: Causal Effects -->

<!-- \large  -->

<!-- - Let $T=$ randomized exposure to immigration news -->
<!-- - Let $M=$ anxiety -->
<!-- - Let $Y=$ opinion on immigration \pause -->


<!-- - Describe the mediation effects -->
<!-- - Describe the direct effects -->


## Moderation and Interaction

<!-- <!--   \item 3rd vars:  primary interest is relationship betwn $T --> 
<!-- <!--     \Rightarrow Y$.  Mod/meds are related to this relationship, but --> 
<!-- <!--     not $T$ or $Y$. --> 
<!-- <!--   \item MEDiators fall betwn $T$ and $Y$, are affected by $Y$.  Are --> 
<!-- <!--     ``mechanisms'', ``pathways''.  Mediation analysis: how much of -->
<!-- <!--     effect of $T$ goes through this mechanism? --> 
<!-- <!--  \item MODerators are pretreatment covariates, but they affect not --> 
<!-- <!--    just {\it level} of $Y_i$ observed (``confounders''), but also size --> 
<!-- <!--    of $TE_i$ --> 
<!-- <!-- \item I.e., controlling for confounders reduces bias in estimate of, --> 
<!-- <!--   e.g., ATE. --> 
<!-- <!-- \item[]  Moderation means we have {\it multiple} causal estimates, one --> 
<!-- <!--   for each level of moderator. --> 

>- Moderators and mediators are both ``third variables\text{''}
>- First, our DAG model for mediation:

\pause

![](figs/02-iktyMedModel.jpg)

\pause

>- What's "moderation"?
>    - When $E(Y_i(1) - Y_i(0) | X = x_1) \neq E(Y_i(1) - Y_i(0) | X
    = x_2)$
>    - When there are ``heterogeneous treatment effects\text{''}
>    - When there is an ``interaction between $T$ and $X$\text{''}

<!-- ## What does Moderation Look Like? -->

<!-- <!-- \begin{center} --> 
<!-- <!--   See {\tt moderation.R}. --> 
<!-- <!-- \end{center} --> 

<!-- <!-- \pause  --> 

<!-- \large  -->

<!-- Notes on interactions: -->

<!-- >- If they are in DGP, omitting can lead to terrible estimates -->
<!-- >    - Include in $p$-score models -->
<!-- >- Ignore stat. sig. of ``main\text{''} linear terms   -->
<!-- [@braumoeller04] -->
<!-- >- Don't fish! -->


<!-- <!-- ``Indirect effect'' definition less clear here than in mediation --> 

<!-- <!-- If offensive, just think ``mediator causal effect''. --> 




## Are 2 Experiments Enough for Mediation CEs?

\begin{itemize}
\item Exp. 1: Randomize $T_i$, measure $M_i$, get ``ACE of $T$ on
  $M$'' \pause
\item Exp. 2: Randomize $M_i$, measure $Y_i$, get ``ACE of $M$ on
  $Y$'' \pause
\item Then, combine somehow, get ACME/Indir. effect of $T$ on $Y$ via $M$?
\pause
\item But, this doesn't get you
  \begin{itemize}
  \item Unbiased estimate \pause
  \item Sign of ACME \pause
  \item Informative bounds for ACME!
  \end{itemize}
\end{itemize}


## Usual (Best-Case?) Way to "Combine Somehow"

"Baron & Kenny Procedure"

\begin{eqnarray}
 M_i  & = & \alpha_1 + a T_i + \epsilon_{i1} \\
 Y_i  & = & \alpha_2 + c T_i + \epsilon_{i2} \\
 Y_i  & = & \alpha_3 + d T_i + bM_i + \epsilon_{i3}
\end{eqnarray}

\pause
(Can add $+ {\bf e}_1 X_i$, $+ {\bf e}_2 X_i$, $+ {\bf e}_3 X_i$.)

\pause

Then, call effect of
\begin{eqnarray*}
T \to M & = & a \\
T \to Y & = & c \qquad \qquad \text{(Total)}\\
T \to Y & = & d \qquad \qquad \text{(Direct)}\\
  M \to Y & = & b \\
T \to M \to Y & = & c-d = ab \qquad
\text{(Mediation)}
\end{eqnarray*}

\pause

Problem: This doesn't work.


## Why Aren't 2 Experiments Enough?

<!-- <!-- \note{Consider table. --> 
<!-- <!--   \begin{itemize} --> 
<!-- <!--   \item Imagine pop with 4 types of people --> 
<!-- <!--   \item Imagine see all potential outcomes (cols 2-5) --> 
<!-- <!-- \item Imagine Tr only affects $Y$ through $M$ediator --> 
<!-- <!-- \item Calculate avg pot. outcomes for various $t$, $m$ (last row) --> 
<!-- <!-- \item Then, easy to do subtraction, calculate effects of $T$ on $M$, --> 
<!-- <!--   $M$ on $Y$ (the ``2 experiments'') --> 
<!-- <!-- \item Also easy to calc. each type's Mediation effect, and average.   --> 
<!-- <!-- \item Clearly, product/difference of Baron-Kenny regression coefs is wrong! --> 
<!-- <!--   \end{itemize} --> 

![](figs/02-iktySItable.jpg)

\pause

\begin{tabular}{lcccc}
$T \to M$ & $=$ & $a$ & $=$ &0.2 \\
$M \to Y$ & $=$ & $b$ & $=$ &0.2 \\
$T \to M \to Y$ & $=$ & $ab$ & $=$ & 0.04
\end{tabular}

\pause

\vspace{1mm}
But, true $\bar{\delta}(t)$, ACME, $=-0.2$!



## What Else Do You Need?

Consistency assumption:  $T_i = t$, $M_i = m$ have same effect
regardless of how they came to have those values.

\pause
\vspace{3mm}

(Using lottery to estimate effect of income on attitude requires
**lottery income**  to have same effect as **regular income**.)

\pause
\vspace{3mm}

The ACME, e.g., is an estimate of the effect of changes in $M$ due to changing
$T$ (but without changing $T$).

\pause
\vspace{3mm}

(Other manipulations of $M$ rely on consistency.)



## What Else Do You Need?

Big picture: to get more detailed estimates from same data, need more assumptions

![](figs/02-iktySeqIgnor.jpg)


## What Else Do You Need?

- Eqn 3: Conditional independence of PotOut's from Tr, given $X$ (pretreatment!)
    - Ok, for random $T$, or balanced obs design.  $T$ as good as random, exog., etc.
    - ($t'$ is just saying, for each $t=0,1$, must have $Y$'s from both
$t=0,1$ must be indep.)
- Eqn 4: Hard.  Mediator is as good as random, given particular Tr
  status
- Problem: can't randomize _both_ $T$ and $M$ in same experiment
    - (if want effect of $T$ through $M$)
- You're getting 2 different QoI's if you randomize both: $T \to M, Y$ and $M
  \to Y$.
    - Showed can't combine those into $T \to M \to Y$

## When Can You Get It?

<!-- <!-- \begin{itemize} --> 
<!-- <!-- \item Problem: $T$ may affect $N$ which may affect $M$  --> 
<!-- <!-- \item[] What about matching/adjusting for $N$?  (No, it's post-Tr!) --> 
<!-- <!-- \item[] In (3), need to adjust for $X$ sometimes -- get balance, find rand. experiment --> 
<!-- <!-- \item[] But, in (4), adjusting for $X$ not enough -- may have --> 
<!-- <!--   imbalance on $N$.  If don't adjust, it's like bad obs. study.  If do --> 
<!-- <!--   adjust, it's like obs. study with post-treatment bias. --> 
<!-- <!-- \item E.g., random ImmigNews.  Knowing $T$ doesn't tell $Y$, $M$ --> 
<!-- <!--   values. --> 
<!-- <!-- \item[] But, if ImmigNews affects both anxiety $M$ and issueAwareness --> 
<!-- <!--   $N$, and issueAwareness affects anxiety $M$, you're in deep. --> 
<!-- <!-- \item Can't even get sensitivity analysis here. --> 
<!-- <!--   \end{itemize} --> 

![](figs/02-iktyMedProblem.jpg)


## Estimating Mediation Effects

<!-- <!--   \begin{itemize} -->
<!-- <!-- \item Generally, combination of model outputs\\ --> 
<!-- <!-- (quasi-Bayes Monte Carlo draws of model --> 
<!-- <!--     parameters procedure) --> 
<!-- <!--   \item BK procedure, using {\tt lm()} is example. --> 
<!-- <!--   \item But estimation doesn't ensure good answer! --> 
<!-- <!--   \item Sensitivity {\it as part of} results summary --> 
<!-- <!--   \end{itemize} --> 


\begin{itemize}
\item Subtlety: $\exists$ causal DAG's for which
    sensitivity of ACME can be est'd; even some with ACME identified. \pause
\item However, must convince that $\nexists$ $N \to M$, whether or not $N$ observed.  \pause
\item Practical advice: start there.  \pause  Then, formal mediation.
\end{itemize}

## Sensitivity for Mediation Effects

<!-- <!-- Sensitivity:  ``How bad would it have to be to change my answer?'' --> 
Given
\begin{eqnarray}
M_i  & = & \alpha_1 + a T_i + \epsilon_{i1} \\
Y_i  & = & \alpha_2 + c T_i + \epsilon_{i2} \\
Y_i  & = & \alpha_3 + d T_i + b M_i + \epsilon_{i3}
\end{eqnarray}

\begin{itemize}
\item Q: How much covariance $\rho$ is there between $\epsilon_{i1}$ and
  $\epsilon_{i3}$? \pause
\item A: If Seq. Ig. is true, then none ($X$-adjustment does its job) \pause
\item[] (If $P$, then $Q$.)  \pause
\item If $\rho \neq 0$, then Seq. Ig. is false (likely hidden
  confounder) \pause
\item[] (If $\lnot Q$, then $\lnot P$.) \pause
\item[] (I.e., From freq. standpoint, you can find ``evidence of problem'', or ``no evidence
  of problem'', but not ``evidence of no problem''.)
\end{itemize}

## Sensitivity for Mediation Effects

<!-- <!--   \begin{itemize} --> 
<!-- <!-- \item Estimate of mediation effect: dashed line. --> 
<!-- <!--   \item Problem: {\it True} value of $\rho$ unknown (``errors'', not --> 
<!-- <!--     ``residuals'') --> 
<!-- <!--   \item So, have to propose range of $\rho_0$ values,\\ figure out: ``given --> 
<!-- <!--     our obs. data $+ \rho_0$, what would true ACME be?'' --> 
<!-- <!--   \item Note: This sensitivity is {\it only} to unobserved --> 
<!-- <!--     pretreatment $X$ confounding --> 
<!-- <!-- \item If $\rho=0$, estimated ACME is true. --> 
<!-- <!-- \item[] If $\rho =.5$, estimated ACME is off from 0 (and big --> 
<!-- <!--   overestimate) --> 
<!-- <!-- \item[] If $\rho =-.75$, estimated ACME is off from truth (and big --> 
<!-- <!--   underestimate) --> 
<!-- <!--   \end{itemize} --> 

![](figs/02-iktyMedSens.jpg){fig_align="center height=85%}


<!-- ## Design for Mediation Effects -->

<!-- @imakeetin11 -->

<!--   <!-- \item Random $T$, measure $M$, measure $Y$ --> 
<!--   <!-- \item Media cues {\it encourage} emotional changes -->
<!--   <!-- \item Parallel: 1) single-exp, 2) another encouragement of emotion --> 
<!--   <!--   change (writing task).  (But, still not ID'ed, relying on --> 
<!--   <!--   assumptions.) --> 
<!--   <!-- \item Combine Parallel with IV, identify the CACME.\\(I.e., get some --> 
<!--   <!--   random variation in $M$ for both the Tr and Co condition subjects) --> 

<!-- \begin{itemize} -->
<!-- \item Single experiment -->
<!-- \item Encouragements-of-mediator experiments -->
<!-- \item Parallel encouragement experiments -->
<!-- \item Parallel encouragement with IV: CACME -->
<!-- \end{itemize} -->



## Summary

- Be careful.  \pause  If you estimate, you must do sensitivity. \pause
    - A serious case of ``don't just get an answer\text{''} \pause
    - (Do `plot(lm_out)`, too \ldots) \pause
- @imakeetin11 thorough on assumptions, when trouble, when
  sensitivity is OK, when identification can be done\pause
- From @bulgreha10:

![](figs/02-bghMedQuote.jpg)



# Sensitivity to an Unobserved Covariates

## Confounding in Observational Studies

```{r warning = FALSE, echo = FALSE}
coords <- list(x = c(T = 0, X = 1, Y = 2), 
               y = c(T = 1, X = 0, Y = 1.1))
dagify(Y ~ T, T ~ X, Y ~ X, coords = coords) |> 
  ggdag_classic(size = 30) + theme_dag_blank()
```

***

```{r dagUnobs, warning=FALSE, echo=FALSE}
coords <- list(x = c(T = 0, X = 1, Y = 2, U = 0.1), 
               y = c(T = 1, X = 0, Y = 1.1, U = 0.1))
dagify(Y ~ T + U, T ~ X + U, Y ~ X, coords = coords, latent = "U") %>% 
  ggdag_classic(size = 30) + theme_dag_blank()
```

## Addressing Confounding

\Large 

To break confounding, 

- can't break $X \to Y$
- break $X \to T$
- I.e., make $X \independent T$
- But this doesn't address $U \to T$ (or $U \to Y$).

\pause 

(Of course, if no causal effect of $U \to Y$, no problem.)


## Hidden Bias

\large 

Where there is $U \to T$ and $U \to Y$, there is _hidden bias_.  

\pause 

Formally, $i$ and $j$ appear similar: $$\mathbf{x}_i = \mathbf{x}_j$$ 

\pause 

but are different in prop score: $$\pi_i \neq \pi_j$$ 


## Example

\large

We are interested in the effect of phone calls on turnout.  

\pause 

Two voters look identical on observed predictors of whether called (that might affect 
turnout, too): age, education, income, party ID.  

\pause 

However, **different** probabilities of being called, due to unobserved confounder, sociability.

\pause 

Sociability affects whether called (know more people) and turnout.

\pause 

Sensitivity: how strong must sociability be to invalidate inference about phone calls?

<!-- # Odds -->

## Odds

The _odds_ of $A_1$ vs. $A_2$ is $$A_1:A_2 = \frac{p(A_1)}{p(A_2)}$$ \pause

Odds often expressed as 

- integers: $3:2$  \pause Know $p(\Omega)=1$, so 
$$3:2 = \frac{.6}{.4}$$  \pause
- base $=1$: $1.5:1$.  \pause Know $p(\Omega)=1$, so 
$$1.5:1 = \frac{.6}{.4}$$ 

## Odds Ratios

An _odds ratio_ is \pause a ratio of odds: \pause 

$$OR = \frac{\left(\frac{p(A_1)}{p(A_2)} \right)}{\left(\frac{p(A_3)}{p(A_4)}\right)}$$ 

\pause 

The strength, and weakness, is comparing changes from different base rates.  

\pause 

\vspace{5mm} From base odds of $1:1$, say a change of condition produces odds ratio of 3. \pause 
$$\frac{\frac{.03}{.01}}{\frac{.01}{.01}} \pause =
\frac{\frac{.06}{.02}}{\frac{.02}{.02}} \pause = 
\frac{\frac{.9}{.3}}{\frac{.3}{.3}} \pause = 
\frac{\frac{.9}{.3}}{\frac{.9}{.9}} \pause = \ldots$$


## Application: Measuring Group Differences (JP Scanlon)

\begin{center}
\begin{tabular}{ccccccc}
& \multicolumn{3}{c}{\% Below Pov Line} & \multicolumn{3}{c}{\% Above
  Pov Line} \\
& B & W & $\frac{B}{W}$ & B & W & $\frac{B}{W}$ \\ \hline
$t_1$ & 90 & 80 & 1.1 & 10 & 20 & 0.5 \\ \pause
$t_2$ & 15 & 5 & 3.0 & 85 & 95 & 0.89
\end{tabular}
\end{center} \pause

\pause 

>- At $t_1$: More blacks below, whites above PovLine
>- At $t_2$: are things getting better or worse for Blacks relative to Whites?

\pause 

Clearly, worse (odds of below pov line):  

Odds Ratios: $\frac{1.1}{.5} = 2.2$, $\frac{3}{.89} = 3.4$

\pause 

Clearly, no change:    

Absolute Differences: 10, 10, 10, 10  

\pause 

Clearly, huge absolute improvements.

## Application: Measuring Group Differences (JP Scanlon)

>- Key: it's not clear whether relative disparities getting better/worse/neither by below/above measures.
>- (Easy to produce examples of OR's same and AbsDiffs slightly diff.)
>- (Diffs betwn groups real, importnt, but how we meas. changes is tricky)

	
## King's Conjecture

<!-- (Unproven; not proven false) -->

\begin{center}
\includegraphics[angle=0, width=4.5in]{figs/02-gkOR-tweet.jpg}

\vspace{15mm}
17 October 2012

\end{center}


<!-- # Rosenbaum's Model -->

## Modeling Hidden Bias

\large

Odds of treatment for $i$ and $j$:

$$\frac{\pi_i}{1 - \pi_i}, \frac{\pi_j}{1 - \pi_j}$$

\pause

OR of $i$ versus $j$:

\begin{eqnarray*}
OR & = & \frac{\pi_i}{1 - \pi_i} \div \frac{\pi_j}{1 - \pi_j} \\
& = & \frac{\pi_i (1 - \pi_j)}{\pi_j (1 - \pi_i)}
\end{eqnarray*}


## Modeling Hidden Bias

\large

Let $\Gamma$ be upper bound on OR of treatment.

$$\frac{1}{\Gamma} \leq \frac{\pi_i (1 - \pi_j)}{\pi_j (1 - \pi_i)} \leq \Gamma \qquad \forall i, j \text{ s.t. } \mathbf{x}_i = \mathbf{x}_j$$

\pause

By what factor does the odds of treatment differ?  (No more than $\Gamma$)

## Modeling Hidden Bias

@rosenbaum20 shows that this is same as

\begin{eqnarray*}
\log \left(\frac{\pi_i}{1-\pi_i} \right) & = & \kappa(\mathbf{x}_i) + \gamma u_i \\
\log \left(\frac{\pi_j}{1-\pi_j} \right) & = & \kappa(\mathbf{x}_j) + \gamma u_j
\end{eqnarray*}

s.t. $0 \leq u_i \leq 1$.

\pause

Interpretation: first rewrite

$$\log \left(\frac{\pi_j}{1-\pi_j} \right) = \kappa(\mathbf{x}_i) + \gamma u_j$$

***

Exponentiate:

\begin{eqnarray*}
\left(\frac{\pi_i}{1-\pi_i} \right) & = & e^{\kappa(\mathbf{x}_i) + \gamma u_i} \\
\left(\frac{\pi_j}{1-\pi_j} \right) & = & e^{\kappa(\mathbf{x}_i) + \gamma u_j} \\
\end{eqnarray*}

\pause

Calculate OR:

\begin{eqnarray*}
OR & = & \frac{\pi_i (1 - \pi_j)}{\pi_j (1 - \pi_i)} \\
& = & \frac{e^{\kappa(\mathbf{x}_i) + \gamma u_i} }{ e^{\kappa(\mathbf{x}_i) + \gamma u_j} } \\
& = & e^{\left(\kappa(\mathbf{x}_i) + \gamma u_i \right) - \left( \kappa(\mathbf{x}_i) + \gamma u_j \right) } \\
& = & e^{\left(\gamma u_i - \gamma u_j \right) } \\
& = & e^{\gamma \left( u_i - u_j \right) }
\end{eqnarray*}

## Interpreting $\Gamma$

\large

$OR = e^{\gamma \left( u_i - u_j \right) }$

\pause

Log odds differ by factor of $\gamma$ times diff in unobs confounder.

\pause

Shows $\Gamma = e^{\gamma}$.


***

<!-- What is the test here?  RTM  -->

![](figs/02-sens-tab1.png)

\pause

<!-- \vspace{5mm} -->

- Groups: smokers/nonsmokers
- Outcome: lung cancer
- Something must increase smoking by $6 \times$ to change inference.
- If exists, maybe it's that factor, not smoking directly.

(Bias from $U \to T$; effectively, $U \to Y$ nearly perfect.)

***

<!-- | $\Gamma$ | Minimum       | Maximum       | -->
<!-- |--------|:--------:|:--------:| -->
<!-- | 1        | $\leq 0.0001$ | $\leq 0.0001$ | -->
<!-- | 2        | $\leq 0.0001$ |    0.0018     | -->
<!-- | 3        | $\leq 0.0001$ |    0.0136     | -->
<!-- | 4        | $\leq 0.0001$ |    0.0388     | -->
<!-- | 4.25     | $\leq 0.0001$ |    0.0468     | -->
<!-- | 5        | $\leq 0.0001$ |    0.0740     | -->

\begin{table}[ht]
    \centering
    % \caption{Example Table}
    \begin{tabular}{c|c|c}
    \hline
    $\Gamma$ & Minimum & Maximum \\
    \hline
    1        & $\leq 0.0001$ & $\leq 0.0001$ \\
    2        & $\leq 0.0001$ & 0.0018 \\
    3        & $\leq 0.0001$ & 0.0136 \\
    4        & $\leq 0.0001$ & 0.0388 \\
    4.25     & $\leq 0.0001$ & 0.0468 \\
    5        & $\leq 0.0001$ & 0.0740 \\
    \hline
    \end{tabular}
\end{table}

\vspace{5mm}

Table 4.2: Signed-Rank Statistic $p$-value Sensitivity for Lead in Children's Blood

- Groups: parents occupationally exposed/unexposed
- Outcome: children's levels
- Something must increase parents' exposure by $5 \times$ to change inference.
- If exists, maybe it's that, not parental exposure directly.

\pause

(one-sided)


***

<!-- | $\Gamma$ | Minimum | Maximum | -->
<!-- | -------- | ------- | ------- | -->
<!-- | 1        | 15      | 15      | -->
<!-- | 2        | 10.25   | 19.5    | -->
<!-- | 3        | 8       | 23      | -->
<!-- | 4        | 6.5     | 25      | -->
<!-- | 5        | 5       | 26.5    | -->

\begin{table}[ht]
    \centering
    % \caption{Example Table}
    \begin{tabular}{c|c|c}
    \hline
    $\Gamma$ & Minimum & Maximum \\
    \hline
    1        & 15      & 15      \\
    2        & 10.25   & 19.5    \\
    3        & 8       & 23      \\
    4        & 6.5     & 25      \\
    5        & 5       & 26.5    \\
    \hline
    \end{tabular}
\end{table}


\vspace{5mm}

Table 4.3: Point Estimate Sensitivity for Lead in Children's Blood

\pause

- HL point estimate: 15
(median of all $m \times n$ possible matched pairs)
- With confounding, wider range of possible effects.



***

<!-- | $\Gamma$ | 95% CI       | -->
<!-- | :------: | :----------: | -->
<!-- | 1        | (9.5, 20.5)  | -->
<!-- | 2        | (4.5, 27.5)  | -->
<!-- | 3        | (1.0, 32.0)  | -->
<!-- | 4        | (-1.0, 36.5) | -->
<!-- | 5        | (-3.0, 41.5) | -->

\begin{table}[ht]
    \centering
    % \caption{Example Table with 95\% Confidence Intervals}
    \begin{tabular}{c|c}
    \hline
    $\Gamma$ & 95\% CI \\
    \hline
    1        & (9.5, 20.5)  \\
    2        & (4.5, 27.5)  \\
    3        & (1.0, 32.0)  \\
    4        & (-1.0, 36.5) \\
    5        & (-3.0, 41.5) \\
    \hline
    \end{tabular}
\end{table}

\vspace{5mm}

Table 4.4: Confidence Interval Sensitivity for Lead in Children's Blood

\pause

- Inverted NHST CI's
- If something increases parental exposure by $4 \times$, negative
estimates of parents on children are reasonable.

(two-sided)


<!-- # Implementation -->

## Implementation

\Large

Packages

- `sensitivitymw`
- `sensitivitymv`
- @framarduo13: `konfound`
- @keele22: `rbounds`


## Implementation in `sensitivitymw`

\large

```{r warning = FALSE, message=FALSE}
library(Matching)
data(GerberGreenImai)

# Estimate Propensity Score
pscore.glm <- glm(PHN.C1 ~ PERSONS + VOTE96.1 +
                    NEW + MAJORPTY + AGE + WARD +
                    PERSONS:VOTE96.1 + PERSONS:NEW +
                    AGE2, family = binomial(logit),
                  data = GerberGreenImai)
```

***

```{r warning = FALSE}
hist(pscore.glm$fitted)
```


## Implementation in `sensitivitymw`

```{r warning = FALSE}
# Match - without replacement

set.seed(758456581)

m.obj <- Match(Y = GerberGreenImai$VOTED98,
               Tr = GerberGreenImai$PHN.C1,
               X = fitted(pscore.glm), M = 1, replace = FALSE)

summary(m.obj)
```


## Implementation in `sensitivitymw`

```{r}
#| label: sensmwpkg
#| eval: true

library(sensitivitymw)

df_matched <- cbind(
  GerberGreenImai$VOTED98[m.obj$index.treated], 
  GerberGreenImai$VOTED98[m.obj$index.control])

df_matched |> head()
```

## Implementation in `sensitivitymw`

```{r}
#| label: sensmw
#| eval: true

gammas <- seq(1, 1.3, by = 0.03)
ps <- vector("numeric", length(gammas))

for(idx in 1:length(gammas)){
  ps[idx] <- senmw(df_matched, gamma = gammas[idx])$pval}

rbind(gammas, ps) |> round(2)
```


## Implementation in `sensitivitymw`

```{r}
data("mercury")
head(mercury)
```

## Implementation in `sensitivitymw`

```{r}
gammas <- seq(10, 20, by = 1)
ps <- vector("numeric", length(gammas))

for(idx in 1:length(gammas)){
  ps[idx] <- senmw(mercury, gamma = gammas[idx])$pval}

rbind(gammas, ps) |> round(2)
```


## Implementation in `konfound`

```{r}
anes <- read_csv("../data/anes_pilot_2016.csv")
dim(anes)

anes <- anes |> mutate(age = 2016 - birthyr,
                       pid_rep = as.numeric(pid3 == 3),
                       pid_dem = as.numeric(pid3 == 1))
```

***

```{r}
lm_out <- lm(turnout12 ~ pid_rep, data = anes)
summary(lm_out)
```


***

```{r warning = FALSE, results = 'hide'}
#| echo: false
#| eval: true

hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
```

```{r warning = FALSE, message=FALSE, linewidth=60, eval=FALSE}
library(konfound)
konfound(lm_out, pid_rep)
```

\pause


```{r warning = FALSE, message=FALSE, linewidth=60, echo=FALSE}
library(konfound)
konfound(lm_out, pid_rep)
```


***

```{r warning = FALSE}
lm_out <- lm(turnout12 ~ pid_rep + age, data = anes)
summary(lm_out)
```

***

```{r warning = FALSE, message=FALSE, linewidth=60}
konfound(lm_out, pid_rep)
```

***

```{r warning = FALSE}
cor(anes[,c("pid_rep", "turnout12", "econnow")])
```

***

```{r warning = FALSE}
lm_out <- lm(turnout12 ~ pid_rep + age + econnow, data = anes)
summary(lm_out)
```

***

```{r warning = FALSE, message=FALSE, linewidth=60}
konfound(lm_out, pid_rep)
```



***

\huge

\begin{center}
Thanks! 
\end{center}

\vspace{5mm}

\large

\begin{center}
\texttt{rtm@american.edu}  \\
\texttt{www.ryantmoore.org}  
\end{center}


## References {.allowframebreaks}

\footnotesize

